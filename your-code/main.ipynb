{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Before-your-start:\" data-toc-modified-id=\"Before-your-start:-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Before your start:</a></span></li><li><span><a href=\"#Challenge-1---Mapping\" data-toc-modified-id=\"Challenge-1---Mapping-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Challenge 1 - Mapping</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#We-will-use-the-map-function-to-clean-up-a-words-in-a-book.\" data-toc-modified-id=\"We-will-use-the-map-function-to-clean-up-a-words-in-a-book.-2.0.0.1\"><span class=\"toc-item-num\">2.0.0.1&nbsp;&nbsp;</span>We will use the map function to clean up a words in a book.</a></span></li><li><span><a href=\"#Let's-remove-the-first-568-words-since-they-contain-information-about-the-book-but-are-not-part-of-the-book-itself.\" data-toc-modified-id=\"Let's-remove-the-first-568-words-since-they-contain-information-about-the-book-but-are-not-part-of-the-book-itself.-2.0.0.2\"><span class=\"toc-item-num\">2.0.0.2&nbsp;&nbsp;</span>Let's remove the first 568 words since they contain information about the book but are not part of the book itself.</a></span></li><li><span><a href=\"#The-next-step-is-to-create-a-function-that-will-remove-references.\" data-toc-modified-id=\"The-next-step-is-to-create-a-function-that-will-remove-references.-2.0.0.3\"><span class=\"toc-item-num\">2.0.0.3&nbsp;&nbsp;</span>The next step is to create a function that will remove references.</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Challenge-2---Filtering\" data-toc-modified-id=\"Challenge-2---Filtering-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Challenge 2 - Filtering</a></span></li><li><span><a href=\"#Bonus-Challenge---Part-1\" data-toc-modified-id=\"Bonus-Challenge---Part-1-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Bonus Challenge - Part 1</a></span></li><li><span><a href=\"#Challenge-3---Reducing\" data-toc-modified-id=\"Challenge-3---Reducing-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Challenge 3 - Reducing</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Now-that-we-have-significantly-cleaned-up-our-text-corpus,-let's-use-the-reduce()-function-to-put-the-words-back-together-into-one-long-string-separated-by-spaces.\" data-toc-modified-id=\"Now-that-we-have-significantly-cleaned-up-our-text-corpus,-let's-use-the-reduce()-function-to-put-the-words-back-together-into-one-long-string-separated-by-spaces.-5.0.0.1\"><span class=\"toc-item-num\">5.0.0.1&nbsp;&nbsp;</span>Now that we have significantly cleaned up our text corpus, let's use the <code>reduce()</code> function to put the words back together into one long string separated by spaces.</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Challenge-4---Applying-Functions-to-DataFrames\" data-toc-modified-id=\"Challenge-4---Applying-Functions-to-DataFrames-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Challenge 4 - Applying Functions to DataFrames</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Our-next-step-is-to-use-the-apply-function-to-a-dataframe-and-transform-all-cells.\" data-toc-modified-id=\"Our-next-step-is-to-use-the-apply-function-to-a-dataframe-and-transform-all-cells.-6.0.0.1\"><span class=\"toc-item-num\">6.0.0.1&nbsp;&nbsp;</span>Our next step is to use the apply function to a dataframe and transform all cells.</a></span></li><li><span><a href=\"#Our-last-challenge-will-be-to-create-an-aggregate-function-and-apply-it-to-a-select-group-of-columns-in-our-dataframe.\" data-toc-modified-id=\"Our-last-challenge-will-be-to-create-an-aggregate-function-and-apply-it-to-a-select-group-of-columns-in-our-dataframe.-6.0.0.2\"><span class=\"toc-item-num\">6.0.0.2&nbsp;&nbsp;</span>Our last challenge will be to create an aggregate function and apply it to a select group of columns in our dataframe.</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Bonus-Challenge---Part-2\" data-toc-modified-id=\"Bonus-Challenge---Part-2-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Bonus Challenge - Part 2</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T21:46:12.408435Z",
     "start_time": "2020-02-21T21:46:11.847469Z"
    }
   },
   "outputs": [],
   "source": [
    "# import reduce from functools, numpy and pandas\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Mapping\n",
    "\n",
    "#### We will use the map function to clean up a words in a book.\n",
    "\n",
    "In the following cell, we will read a text file containing the book The Prophet by Khalil Gibran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T21:49:44.195701Z",
     "start_time": "2020-02-21T21:49:44.190753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "location = '../58585-0.txt'\n",
    "with open(location, 'r', encoding=\"utf8\") as f:\n",
    "    prophet = f.read().split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's remove the first 568 words since they contain information about the book but are not part of the book itself. \n",
    "\n",
    "Do this by removing from `prophet` elements 0 through 567 of the list (you can also do this by keeping elements 568 through the last element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T21:54:26.876740Z",
     "start_time": "2020-02-21T21:54:26.873741Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "prophet = prophet[:567]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look through the words, you will find that many words have a reference attached to them. For example, let's look at words 1 through 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T21:54:45.081021Z",
     "start_time": "2020-02-21T21:54:45.072118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Prophet,',\n",
       " 'by',\n",
       " 'Kahlil']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "prophet[0:9]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is to create a function that will remove references. \n",
    "\n",
    "We will do this by splitting the string on the `{` character and keeping only the part before this character. Write your function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T21:56:31.751676Z",
     "start_time": "2020-02-21T21:56:31.747641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n"
     ]
    }
   ],
   "source": [
    "def reference(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: The string with references removed\n",
    "    \n",
    "    Example:\n",
    "    Input: 'the{7}'\n",
    "    Output: 'the'\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    return x.split('{')[0]\n",
    "        \n",
    "print(reference('the{7}'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our function, use the `map()` function to apply this function to our book, The Prophet. Return the resulting list to a new list called `prophet_reference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T21:58:46.063079Z",
     "start_time": "2020-02-21T21:58:46.054729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Prophet,',\n",
       " 'by',\n",
       " 'Kahlil',\n",
       " 'Gibran\\n\\nThis',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'and\\nmost',\n",
       " 'other',\n",
       " 'parts',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions\\nwhatsoever.',\n",
       " '',\n",
       " 'You',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it,',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'terms\\nof',\n",
       " 'the',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'License',\n",
       " 'included',\n",
       " 'with',\n",
       " 'this',\n",
       " 'eBook',\n",
       " 'or',\n",
       " 'online',\n",
       " 'at\\nwww.gutenberg.org.',\n",
       " '',\n",
       " 'If',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'located',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States,',\n",
       " \"you'll\\nhave\",\n",
       " 'to',\n",
       " 'check',\n",
       " 'the',\n",
       " 'laws',\n",
       " 'of',\n",
       " 'the',\n",
       " 'country',\n",
       " 'where',\n",
       " 'you',\n",
       " 'are',\n",
       " 'located',\n",
       " 'before',\n",
       " 'using\\nthis',\n",
       " 'ebook.\\n\\n\\n\\nTitle:',\n",
       " 'The',\n",
       " 'Prophet\\n\\nAuthor:',\n",
       " 'Kahlil',\n",
       " 'Gibran\\n\\nRelease',\n",
       " 'Date:',\n",
       " 'January',\n",
       " '1,',\n",
       " '2019',\n",
       " '[EBook',\n",
       " '#58585]\\nLast',\n",
       " 'Updated:',\n",
       " 'January',\n",
       " '3,',\n",
       " '2018\\n\\n\\nLanguage:',\n",
       " 'English\\n\\nCharacter',\n",
       " 'set',\n",
       " 'encoding:',\n",
       " 'UTF-8\\n\\n***',\n",
       " 'START',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'PROJECT',\n",
       " 'GUTENBERG',\n",
       " 'EBOOK',\n",
       " 'THE',\n",
       " 'PROPHET',\n",
       " '***\\n\\n\\n\\n\\nProduced',\n",
       " 'by',\n",
       " 'David',\n",
       " 'Widger',\n",
       " 'from',\n",
       " 'page',\n",
       " 'images',\n",
       " 'generously\\nprovided',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Internet',\n",
       " \"Archive\\n\\n\\nTranscriber's\",\n",
       " 'Note:',\n",
       " 'Page',\n",
       " 'numbers,',\n",
       " 'ie:',\n",
       " '',\n",
       " 'are',\n",
       " 'included',\n",
       " 'in',\n",
       " 'this\\nutf-8',\n",
       " 'text',\n",
       " 'file.',\n",
       " 'For',\n",
       " 'those',\n",
       " 'wishing',\n",
       " 'to',\n",
       " 'use',\n",
       " 'a',\n",
       " 'text',\n",
       " 'file',\n",
       " 'unencumbered\\nwith',\n",
       " 'page',\n",
       " 'numbers',\n",
       " 'open',\n",
       " 'or',\n",
       " 'download',\n",
       " 'the',\n",
       " 'Latin-1',\n",
       " 'file',\n",
       " '58585-8.txt.\\n\\n\\n\\n\\n\\n\\n\\nTHE',\n",
       " 'PROPHET\\n\\nBy',\n",
       " 'Kahlil',\n",
       " 'Gibran\\n\\nNew',\n",
       " 'York:',\n",
       " 'Alfred',\n",
       " 'A.',\n",
       " 'Knopf\\n\\n1923\\n\\n_The',\n",
       " 'Twelve',\n",
       " 'Illustrations',\n",
       " 'In',\n",
       " 'This',\n",
       " 'Volume\\nAre',\n",
       " 'Reproduced',\n",
       " 'From',\n",
       " 'Original',\n",
       " 'Drawings',\n",
       " 'By\\nThe',\n",
       " 'Author_\\n\\n\\n“His',\n",
       " 'power',\n",
       " 'came',\n",
       " 'from',\n",
       " 'some',\n",
       " 'great',\n",
       " 'reservoir\\nof',\n",
       " 'spiritual',\n",
       " 'life',\n",
       " 'else',\n",
       " 'it',\n",
       " 'could',\n",
       " 'not',\n",
       " 'have\\nbeen',\n",
       " 'so',\n",
       " 'universal',\n",
       " 'and',\n",
       " 'so',\n",
       " 'potent,',\n",
       " 'but',\n",
       " 'the\\nmajesty',\n",
       " 'and',\n",
       " 'beauty',\n",
       " 'of',\n",
       " 'the',\n",
       " 'language',\n",
       " 'with\\nwhich',\n",
       " 'he',\n",
       " 'clothed',\n",
       " 'it',\n",
       " 'were',\n",
       " 'all',\n",
       " 'his',\n",
       " 'own?”\\n\\n--Claude',\n",
       " 'Bragdon\\n\\n\\nTHE',\n",
       " 'BOOKS',\n",
       " 'OF',\n",
       " 'KAHLIL',\n",
       " 'GIBRAN\\n\\nThe',\n",
       " 'Madman.',\n",
       " '1918',\n",
       " 'Twenty',\n",
       " 'Drawings.',\n",
       " '1919\\nThe',\n",
       " 'Forerunner.',\n",
       " '1920',\n",
       " 'The',\n",
       " 'Prophet.',\n",
       " '1923\\nSand',\n",
       " 'and',\n",
       " 'Foam.',\n",
       " '1926',\n",
       " 'Jesus',\n",
       " 'the',\n",
       " 'Son',\n",
       " 'of\\nMan.',\n",
       " '1928',\n",
       " 'The',\n",
       " 'Forth',\n",
       " 'Gods.',\n",
       " '1931',\n",
       " 'The\\nWanderer.',\n",
       " '1932',\n",
       " 'The',\n",
       " 'Garden',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Prophet\\n1933',\n",
       " 'Prose',\n",
       " 'Poems.',\n",
       " '1934',\n",
       " 'Nymphs',\n",
       " 'of',\n",
       " 'the\\nValley.',\n",
       " '1948\\n\\n\\n\\n\\nCONTENTS\\n\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The',\n",
       " 'Coming',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Ship.......7\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Love.....................15\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Marriage.................19\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Children.................21\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Giving...................23\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Eating',\n",
       " 'and',\n",
       " 'Drinking......27\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Work.....................31\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Joy',\n",
       " 'and',\n",
       " 'Sorrow...........33\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Houses...................37\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Clothes..................41\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Buying',\n",
       " 'and',\n",
       " 'Selling.......43\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment.....45\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Laws.....................51\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Freedom..................55\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Reason',\n",
       " 'and',\n",
       " 'Passion.......57\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Pain.....................60\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Self-Knowledge...........62\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Teaching.................64\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Friendship...............66\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Talking..................68\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Time.....................70\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Good',\n",
       " 'and',\n",
       " 'Evil............72\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Prayer...................76\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Pleasure.................79\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Beauty...................83\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Religion.................87\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Death....................90\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "prophet_reference = list(map(reference, prophet))\n",
    "\n",
    "prophet_reference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing you may have noticed is that some words contain a line break. Let's write a function to split those words. Our function will return the string split on the character `\\n`. Write your function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T22:04:31.108081Z",
     "start_time": "2020-02-21T22:04:31.104275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'string']\n"
     ]
    }
   ],
   "source": [
    "def line_break(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: A list of strings split on the line break (\\n) character\n",
    "        \n",
    "    Example:\n",
    "    Input: 'the\\nbeloved'\n",
    "    Output: ['the', 'beloved']\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "    return x.split('\\n')\n",
    "\n",
    "print(line_break('a\\nstring'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `line_break` function to the `prophet_reference` list. Name the new list `prophet_line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T22:05:00.853905Z",
     "start_time": "2020-02-21T22:05:00.839146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\\ufeffThe'],\n",
       " ['Project'],\n",
       " ['Gutenberg'],\n",
       " ['EBook'],\n",
       " ['of'],\n",
       " ['The'],\n",
       " ['Prophet,'],\n",
       " ['by'],\n",
       " ['Kahlil'],\n",
       " ['Gibran', '', 'This'],\n",
       " ['eBook'],\n",
       " ['is'],\n",
       " ['for'],\n",
       " ['the'],\n",
       " ['use'],\n",
       " ['of'],\n",
       " ['anyone'],\n",
       " ['anywhere'],\n",
       " ['in'],\n",
       " ['the'],\n",
       " ['United'],\n",
       " ['States'],\n",
       " ['and', 'most'],\n",
       " ['other'],\n",
       " ['parts'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['world'],\n",
       " ['at'],\n",
       " ['no'],\n",
       " ['cost'],\n",
       " ['and'],\n",
       " ['with'],\n",
       " ['almost'],\n",
       " ['no'],\n",
       " ['restrictions', 'whatsoever.'],\n",
       " [''],\n",
       " ['You'],\n",
       " ['may'],\n",
       " ['copy'],\n",
       " ['it,'],\n",
       " ['give'],\n",
       " ['it'],\n",
       " ['away'],\n",
       " ['or'],\n",
       " ['re-use'],\n",
       " ['it'],\n",
       " ['under'],\n",
       " ['the'],\n",
       " ['terms', 'of'],\n",
       " ['the'],\n",
       " ['Project'],\n",
       " ['Gutenberg'],\n",
       " ['License'],\n",
       " ['included'],\n",
       " ['with'],\n",
       " ['this'],\n",
       " ['eBook'],\n",
       " ['or'],\n",
       " ['online'],\n",
       " ['at', 'www.gutenberg.org.'],\n",
       " [''],\n",
       " ['If'],\n",
       " ['you'],\n",
       " ['are'],\n",
       " ['not'],\n",
       " ['located'],\n",
       " ['in'],\n",
       " ['the'],\n",
       " ['United'],\n",
       " ['States,'],\n",
       " [\"you'll\", 'have'],\n",
       " ['to'],\n",
       " ['check'],\n",
       " ['the'],\n",
       " ['laws'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['country'],\n",
       " ['where'],\n",
       " ['you'],\n",
       " ['are'],\n",
       " ['located'],\n",
       " ['before'],\n",
       " ['using', 'this'],\n",
       " ['ebook.', '', '', '', 'Title:'],\n",
       " ['The'],\n",
       " ['Prophet', '', 'Author:'],\n",
       " ['Kahlil'],\n",
       " ['Gibran', '', 'Release'],\n",
       " ['Date:'],\n",
       " ['January'],\n",
       " ['1,'],\n",
       " ['2019'],\n",
       " ['[EBook'],\n",
       " ['#58585]', 'Last'],\n",
       " ['Updated:'],\n",
       " ['January'],\n",
       " ['3,'],\n",
       " ['2018', '', '', 'Language:'],\n",
       " ['English', '', 'Character'],\n",
       " ['set'],\n",
       " ['encoding:'],\n",
       " ['UTF-8', '', '***'],\n",
       " ['START'],\n",
       " ['OF'],\n",
       " ['THIS'],\n",
       " ['PROJECT'],\n",
       " ['GUTENBERG'],\n",
       " ['EBOOK'],\n",
       " ['THE'],\n",
       " ['PROPHET'],\n",
       " ['***', '', '', '', '', 'Produced'],\n",
       " ['by'],\n",
       " ['David'],\n",
       " ['Widger'],\n",
       " ['from'],\n",
       " ['page'],\n",
       " ['images'],\n",
       " ['generously', 'provided'],\n",
       " ['by'],\n",
       " ['the'],\n",
       " ['Internet'],\n",
       " ['Archive', '', '', \"Transcriber's\"],\n",
       " ['Note:'],\n",
       " ['Page'],\n",
       " ['numbers,'],\n",
       " ['ie:'],\n",
       " ['{20},'],\n",
       " ['are'],\n",
       " ['included'],\n",
       " ['in'],\n",
       " ['this', 'utf-8'],\n",
       " ['text'],\n",
       " ['file.'],\n",
       " ['For'],\n",
       " ['those'],\n",
       " ['wishing'],\n",
       " ['to'],\n",
       " ['use'],\n",
       " ['a'],\n",
       " ['text'],\n",
       " ['file'],\n",
       " ['unencumbered', 'with'],\n",
       " ['page'],\n",
       " ['numbers'],\n",
       " ['open'],\n",
       " ['or'],\n",
       " ['download'],\n",
       " ['the'],\n",
       " ['Latin-1'],\n",
       " ['file'],\n",
       " ['58585-8.txt.', '', '', '', '', '', '', '', 'THE'],\n",
       " ['PROPHET', '', 'By'],\n",
       " ['Kahlil'],\n",
       " ['Gibran', '', 'New'],\n",
       " ['York:'],\n",
       " ['Alfred'],\n",
       " ['A.'],\n",
       " ['Knopf', '', '1923', '', '_The'],\n",
       " ['Twelve'],\n",
       " ['Illustrations'],\n",
       " ['In'],\n",
       " ['This'],\n",
       " ['Volume', 'Are'],\n",
       " ['Reproduced'],\n",
       " ['From'],\n",
       " ['Original'],\n",
       " ['Drawings'],\n",
       " ['By', 'The'],\n",
       " ['Author_', '', '', '“His'],\n",
       " ['power'],\n",
       " ['came'],\n",
       " ['from'],\n",
       " ['some'],\n",
       " ['great'],\n",
       " ['reservoir', 'of'],\n",
       " ['spiritual'],\n",
       " ['life'],\n",
       " ['else'],\n",
       " ['it'],\n",
       " ['could'],\n",
       " ['not'],\n",
       " ['have', 'been'],\n",
       " ['so'],\n",
       " ['universal'],\n",
       " ['and'],\n",
       " ['so'],\n",
       " ['potent,'],\n",
       " ['but'],\n",
       " ['the', 'majesty'],\n",
       " ['and'],\n",
       " ['beauty'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['language'],\n",
       " ['with', 'which'],\n",
       " ['he'],\n",
       " ['clothed'],\n",
       " ['it'],\n",
       " ['were'],\n",
       " ['all'],\n",
       " ['his'],\n",
       " ['own?”', '', '--Claude'],\n",
       " ['Bragdon', '', '', 'THE'],\n",
       " ['BOOKS'],\n",
       " ['OF'],\n",
       " ['KAHLIL'],\n",
       " ['GIBRAN', '', 'The'],\n",
       " ['Madman.'],\n",
       " ['1918'],\n",
       " ['Twenty'],\n",
       " ['Drawings.'],\n",
       " ['1919', 'The'],\n",
       " ['Forerunner.'],\n",
       " ['1920'],\n",
       " ['The'],\n",
       " ['Prophet.'],\n",
       " ['1923', 'Sand'],\n",
       " ['and'],\n",
       " ['Foam.'],\n",
       " ['1926'],\n",
       " ['Jesus'],\n",
       " ['the'],\n",
       " ['Son'],\n",
       " ['of', 'Man.'],\n",
       " ['1928'],\n",
       " ['The'],\n",
       " ['Forth'],\n",
       " ['Gods.'],\n",
       " ['1931'],\n",
       " ['The', 'Wanderer.'],\n",
       " ['1932'],\n",
       " ['The'],\n",
       " ['Garden'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['Prophet', '1933'],\n",
       " ['Prose'],\n",
       " ['Poems.'],\n",
       " ['1934'],\n",
       " ['Nymphs'],\n",
       " ['of'],\n",
       " ['the', 'Valley.'],\n",
       " ['1948', '', '', '', '', 'CONTENTS', '', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['The'],\n",
       " ['Coming'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['Ship.......7', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Love.....................15', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Marriage.................19', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Children.................21', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Giving...................23', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Eating'],\n",
       " ['and'],\n",
       " ['Drinking......27', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Work.....................31', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Joy'],\n",
       " ['and'],\n",
       " ['Sorrow...........33', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Houses...................37', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Clothes..................41', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Buying'],\n",
       " ['and'],\n",
       " ['Selling.......43', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Crime'],\n",
       " ['and'],\n",
       " ['Punishment.....45', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Laws.....................51', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Freedom..................55', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Reason'],\n",
       " ['and'],\n",
       " ['Passion.......57', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Pain.....................60', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Self-Knowledge...........62', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Teaching.................64', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Friendship...............66', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Talking..................68', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Time.....................70', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Good'],\n",
       " ['and'],\n",
       " ['Evil............72', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Prayer...................76', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Pleasure.................79', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Beauty...................83', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Religion.................87', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['On'],\n",
       " ['Death....................90', ''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['The']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "prophet_line = list(map(line_break, prophet))\n",
    "prophet_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the elements of `prophet_line`, you will see that the function returned lists and not strings. Our list is now a list of lists. Flatten the list using list comprehension. Assign this new list to `prophet_flat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T22:08:32.718345Z",
     "start_time": "2020-02-21T22:08:32.710301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Prophet,',\n",
       " 'by',\n",
       " 'Kahlil',\n",
       " 'Gibran',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'and',\n",
       " 'other',\n",
       " 'parts',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " '',\n",
       " 'You',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it,',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'the',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'License',\n",
       " 'included',\n",
       " 'with',\n",
       " 'this',\n",
       " 'eBook',\n",
       " 'or',\n",
       " 'online',\n",
       " 'at',\n",
       " '',\n",
       " 'If',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'located',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States,',\n",
       " \"you'll\",\n",
       " 'to',\n",
       " 'check',\n",
       " 'the',\n",
       " 'laws',\n",
       " 'of',\n",
       " 'the',\n",
       " 'country',\n",
       " 'where',\n",
       " 'you',\n",
       " 'are',\n",
       " 'located',\n",
       " 'before',\n",
       " 'using',\n",
       " 'ebook.',\n",
       " 'The',\n",
       " 'Prophet',\n",
       " 'Kahlil',\n",
       " 'Gibran',\n",
       " 'Date:',\n",
       " 'January',\n",
       " '1,',\n",
       " '2019',\n",
       " '[EBook',\n",
       " '#58585]',\n",
       " 'Updated:',\n",
       " 'January',\n",
       " '3,',\n",
       " '2018',\n",
       " 'English',\n",
       " 'set',\n",
       " 'encoding:',\n",
       " 'UTF-8',\n",
       " 'START',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'PROJECT',\n",
       " 'GUTENBERG',\n",
       " 'EBOOK',\n",
       " 'THE',\n",
       " 'PROPHET',\n",
       " '***',\n",
       " 'by',\n",
       " 'David',\n",
       " 'Widger',\n",
       " 'from',\n",
       " 'page',\n",
       " 'images',\n",
       " 'generously',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Internet',\n",
       " 'Archive',\n",
       " 'Note:',\n",
       " 'Page',\n",
       " 'numbers,',\n",
       " 'ie:',\n",
       " '{20},',\n",
       " 'are',\n",
       " 'included',\n",
       " 'in',\n",
       " 'this',\n",
       " 'text',\n",
       " 'file.',\n",
       " 'For',\n",
       " 'those',\n",
       " 'wishing',\n",
       " 'to',\n",
       " 'use',\n",
       " 'a',\n",
       " 'text',\n",
       " 'file',\n",
       " 'unencumbered',\n",
       " 'page',\n",
       " 'numbers',\n",
       " 'open',\n",
       " 'or',\n",
       " 'download',\n",
       " 'the',\n",
       " 'Latin-1',\n",
       " 'file',\n",
       " '58585-8.txt.',\n",
       " 'PROPHET',\n",
       " 'Kahlil',\n",
       " 'Gibran',\n",
       " 'York:',\n",
       " 'Alfred',\n",
       " 'A.',\n",
       " 'Knopf',\n",
       " 'Twelve',\n",
       " 'Illustrations',\n",
       " 'In',\n",
       " 'This',\n",
       " 'Volume',\n",
       " 'Reproduced',\n",
       " 'From',\n",
       " 'Original',\n",
       " 'Drawings',\n",
       " 'By',\n",
       " 'Author_',\n",
       " 'power',\n",
       " 'came',\n",
       " 'from',\n",
       " 'some',\n",
       " 'great',\n",
       " 'reservoir',\n",
       " 'spiritual',\n",
       " 'life',\n",
       " 'else',\n",
       " 'it',\n",
       " 'could',\n",
       " 'not',\n",
       " 'have',\n",
       " 'so',\n",
       " 'universal',\n",
       " 'and',\n",
       " 'so',\n",
       " 'potent,',\n",
       " 'but',\n",
       " 'the',\n",
       " 'and',\n",
       " 'beauty',\n",
       " 'of',\n",
       " 'the',\n",
       " 'language',\n",
       " 'with',\n",
       " 'he',\n",
       " 'clothed',\n",
       " 'it',\n",
       " 'were',\n",
       " 'all',\n",
       " 'his',\n",
       " 'own?”',\n",
       " 'Bragdon',\n",
       " 'BOOKS',\n",
       " 'OF',\n",
       " 'KAHLIL',\n",
       " 'GIBRAN',\n",
       " 'Madman.',\n",
       " '1918',\n",
       " 'Twenty',\n",
       " 'Drawings.',\n",
       " '1919',\n",
       " 'Forerunner.',\n",
       " '1920',\n",
       " 'The',\n",
       " 'Prophet.',\n",
       " '1923',\n",
       " 'and',\n",
       " 'Foam.',\n",
       " '1926',\n",
       " 'Jesus',\n",
       " 'the',\n",
       " 'Son',\n",
       " 'of',\n",
       " '1928',\n",
       " 'The',\n",
       " 'Forth',\n",
       " 'Gods.',\n",
       " '1931',\n",
       " 'The',\n",
       " '1932',\n",
       " 'The',\n",
       " 'Garden',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Prophet',\n",
       " 'Prose',\n",
       " 'Poems.',\n",
       " '1934',\n",
       " 'Nymphs',\n",
       " 'of',\n",
       " 'the',\n",
       " '1948',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The',\n",
       " 'Coming',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Ship.......7',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Love.....................15',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Marriage.................19',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Children.................21',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Giving...................23',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Eating',\n",
       " 'and',\n",
       " 'Drinking......27',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Work.....................31',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Joy',\n",
       " 'and',\n",
       " 'Sorrow...........33',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Houses...................37',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Clothes..................41',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Buying',\n",
       " 'and',\n",
       " 'Selling.......43',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment.....45',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Laws.....................51',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Freedom..................55',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Reason',\n",
       " 'and',\n",
       " 'Passion.......57',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Pain.....................60',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Self-Knowledge...........62',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Teaching.................64',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Friendship...............66',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Talking..................68',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Time.....................70',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Good',\n",
       " 'and',\n",
       " 'Evil............72',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Prayer...................76',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Pleasure.................79',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Beauty...................83',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Religion.................87',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'On',\n",
       " 'Death....................90',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "prophet_flat = [word[0] for word in prophet_line]\n",
    "\n",
    "prophet_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Filtering\n",
    "\n",
    "When printing out a few words from the book, we see that there are words that we may not want to keep if we choose to analyze the corpus of text. Below is a list of words that we would like to get rid of. Create a function that will return false if it contains a word from the list of words specified and true otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T23:17:03.895195Z",
     "start_time": "2020-02-21T23:17:03.890209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_filter(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: true if the word is not in the specified list and false if the word is in the list\n",
    "        \n",
    "    Example:\n",
    "    word list = ['and', 'the']\n",
    "    Input: 'and'\n",
    "    Output: False\n",
    "    \n",
    "    Input: 'John'\n",
    "    Output: True\n",
    "    '''\n",
    "    \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    if x in word_list:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "word_filter('And')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `filter()` function to filter out the words speficied in the `word_filter()` function. Store the filtered list in the variable `prophet_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T22:33:47.358272Z",
     "start_time": "2020-02-21T22:33:47.354064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_filter = list(filter(word_filter, prophet_flat))\n",
    "\n",
    "'and' in prophet_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge - Part 1\n",
    "\n",
    "Rewrite the `word_filter` function above to not be case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T23:17:47.372914Z",
     "start_time": "2020-02-21T23:17:47.368207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def word_filter_case(x):\n",
    "   \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    x = x.lower()\n",
    "    \n",
    "    if x in word_list:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "print(word_filter_case('And'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Reducing\n",
    "\n",
    "#### Now that we have significantly cleaned up our text corpus, let's use the `reduce()` function to put the words back together into one long string separated by spaces. \n",
    "\n",
    "We will start by writing a function that takes two strings and concatenates them together with a space between the two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T23:18:38.497314Z",
     "start_time": "2020-02-21T23:18:38.493096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a string'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_space(a, b):\n",
    "    '''\n",
    "    Input:Two strings\n",
    "    Output: A single string separated by a space\n",
    "        \n",
    "    Example:\n",
    "    Input: 'John', 'Smith'\n",
    "    Output: 'John Smith'\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    return a + ' ' + b\n",
    "    \n",
    "concat_space('a', 'string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to reduce the text corpus in the list `prophet_filter` into a single string. Assign this new string to the variable `prophet_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T23:19:31.998232Z",
     "start_time": "2020-02-21T23:19:31.994165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ufeffThe Project Gutenberg EBook of The Prophet, by Kahlil Gibran eBook is for use of anyone anywhere in United States other parts of world at no cost with almost no restrictions  You may copy it, give it away or re-use it under terms Project Gutenberg License included with this eBook or online at  If you are not located in United States, you'll to check laws of country where you are located before using ebook. The Prophet Kahlil Gibran Date: January 1, 2019 [EBook #58585] Updated: January 3, 2018 English set encoding: UTF-8 START OF THIS PROJECT GUTENBERG EBOOK THE PROPHET *** by David Widger from page images generously by Internet Archive Note: Page numbers, ie: {20}, are included in this text file. For those wishing to use text file unencumbered page numbers open or download Latin-1 file 58585-8.txt. PROPHET Kahlil Gibran York: Alfred A. Knopf Twelve Illustrations In This Volume Reproduced From Original Drawings By Author_ power came from some great reservoir spiritual life else it could not have so universal so potent, but beauty of language with he clothed it were all his own?” Bragdon BOOKS OF KAHLIL GIBRAN Madman. 1918 Twenty Drawings. 1919 Forerunner. 1920 The Prophet. 1923 Foam. 1926 Jesus Son of 1928 The Forth Gods. 1931 The 1932 The Garden of Prophet Prose Poems. 1934 Nymphs of 1948          The Coming of Ship.......7          On Love.....................15          On Marriage.................19          On Children.................21          On Giving...................23          On Eating Drinking......27          On Work.....................31          On Joy Sorrow...........33          On Houses...................37          On Clothes..................41          On Buying Selling.......43          On Crime Punishment.....45          On Laws.....................51          On Freedom..................55          On Reason Passion.......57          On Pain.....................60          On Self-Knowledge...........62          On Teaching.................64          On Friendship...............66          On Talking..................68          On Time.....................70          On Good Evil............72          On Prayer...................76          On Pleasure.................79          On Beauty...................83          On Religion.................87          On Death....................90          The\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "prophet_string = reduce(concat_space, prophet_filter)\n",
    "\n",
    "prophet_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Applying Functions to DataFrames\n",
    "\n",
    "#### Our next step is to use the apply function to a dataframe and transform all cells.\n",
    "\n",
    "To do this, we will load a dataset below and then write a function that will perform the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T23:19:51.314509Z",
     "start_time": "2020-02-21T23:19:48.554929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "# The dataset below contains information about pollution from PM2.5 particles in Beijing \n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00381/PRSA_data_2010.1.1-2014.12.31.csv\"\n",
    "pm25 = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data using the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T23:19:54.410150Z",
     "start_time": "2020-02-21T23:19:54.394735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "pm25.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a function that divides a cell by 24 to produce an hourly figure. Write the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T23:20:09.885938Z",
     "start_time": "2020-02-21T23:20:09.882960Z"
    }
   },
   "outputs": [],
   "source": [
    "def hourly(x):\n",
    "    '''\n",
    "    Input: A numerical value\n",
    "    Output: The value divided by 24\n",
    "        \n",
    "    Example:\n",
    "    Input: 48\n",
    "    Output: 2.0\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    return x/24\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this function to the columns `Iws`, `Is`, and `Ir`. Store this new dataframe in the variable `pm25_hourly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T23:24:27.391391Z",
     "start_time": "2020-02-21T23:24:27.353133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "pm25_hourly = pm25[['Iws', 'Is', 'Ir']].apply(hourly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T23:44:08.975144Z",
     "start_time": "2020-02-21T23:44:08.965446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.074583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.279583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.540417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43819</td>\n",
       "      <td>9.665417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43820</td>\n",
       "      <td>9.907500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43821</td>\n",
       "      <td>10.112500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43822</td>\n",
       "      <td>10.280000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43823</td>\n",
       "      <td>10.410417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43824 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Iws   Is   Ir\n",
       "0       0.074583  0.0  0.0\n",
       "1       0.205000  0.0  0.0\n",
       "2       0.279583  0.0  0.0\n",
       "3       0.410000  0.0  0.0\n",
       "4       0.540417  0.0  0.0\n",
       "...          ...  ...  ...\n",
       "43819   9.665417  0.0  0.0\n",
       "43820   9.907500  0.0  0.0\n",
       "43821  10.112500  0.0  0.0\n",
       "43822  10.280000  0.0  0.0\n",
       "43823  10.410417  0.0  0.0\n",
       "\n",
       "[43824 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our last challenge will be to create an aggregate function and apply it to a select group of columns in our dataframe.\n",
    "\n",
    "Write a function that returns the standard deviation of a column divided by the length of a column minus 1. Since we are using pandas, do not use the `len()` function. One alternative is to use `count()`. Also, use the numpy version of standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T23:45:52.357207Z",
     "start_time": "2020-02-21T23:45:52.354016Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_sd(x):\n",
    "    '''\n",
    "    Input: A Pandas series of values\n",
    "    Output: the standard deviation divided by the number of elements in the series\n",
    "        \n",
    "    Example:\n",
    "    Input: pd.Series([1,2,3,4])\n",
    "    Output: 0.3726779962\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "    return np.std(x) / x.count()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T23:46:29.640996Z",
     "start_time": "2020-02-21T23:46:29.616049Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2fe76899c938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm25_hourly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Iws'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4040\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4041\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4042\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-cd7e56c827f4>\u001b[0m in \u001b[0;36msample_sd\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Your code here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'count'"
     ]
    }
   ],
   "source": [
    "display(pm25_hourly['Iws'].apply(sample_sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the range (max - min) for the columns: pm2.5,DEWP,TEMP,PRES. Ensure we do not return NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T08:22:31.425139Z",
     "start_time": "2019-07-14T08:22:31.420985Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
